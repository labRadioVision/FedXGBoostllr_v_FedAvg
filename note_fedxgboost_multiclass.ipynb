{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries \n",
    "Choose a dataset and set simulation parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "num_classes = 2 # number of classes (=2: binary >2: multiclass)\n",
    "n_features = 50 # number of features in the dataset (TRUSTroke: 63)\n",
    "n_redundant = 5 # redundant features (TRUSTroke: unclear)\n",
    "n_informative = n_features - n_redundant # informative features\n",
    "test_size = 0.4 # fraction of data used for validation\n",
    "training_samples = 1000\n",
    "n_samples = round(training_samples/(1-test_size)) # total samples including also validation set and so that the fraction of data used for validation is test_size \n",
    "random_state = 42\n",
    "# load a tabular dataset for multiclass classification (example with scikitlearn datasets)\n",
    "X, y = datasets.make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_informative, n_redundant=n_redundant, n_classes=num_classes)\n",
    "x_train, x_valid,  y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state)    \n",
    "# save\n",
    "with open(f\"dataset/dataset_{num_classes}_redundant_{n_redundant}.pkl\", \"wb\") as f:\n",
    "    pickle.dump([x_train, x_valid,  y_train, y_valid], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets the number of clients, the training samples per client and the number of trees (xgboost) per client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10  # number of FL clients\n",
    "trees_client = 10  # number of xgboost trees per client\n",
    "samples = round(training_samples/num_clients) # number of training examples per client\n",
    "\n",
    "# load the dataset\n",
    "with open(f\"dataset/dataset_{num_classes}_redundant_{n_redundant}.pkl\", 'rb') as f:\n",
    "    x_train, x_valid,  y_train, y_valid = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized performance\n",
    "Data are fused on the server, this is the classical distributed xboost, privacy critical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_models/XGB_centralized_model.h5']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from utils import accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# xgboost parameters (example)\n",
    "hyperparams = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    # Same number of trees as in the decentralized case\n",
    "    \"n_estimators\": trees_client,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"base_score\": 0.5,\n",
    "    \"random_state\": 34,\n",
    "}\n",
    "if num_classes ==2:\n",
    "    hyperparams[\"objective\"] = \"binary:logistic\"\n",
    "    \n",
    "reg = xgb.XGBClassifier(**hyperparams)\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_valid)\n",
    "accuracy_s = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_s:.2f}\") \n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "# save and store the centralized model\n",
    "checkpointpath1 = 'xgb_models/XGB_centralized_model.h5'\n",
    "joblib.dump(reg, checkpointpath1, compress=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolated case (no federation) \n",
    "Training of local xgboost models (base models of the ensemble)\n",
    "\n",
    "Code below implements iid/uniform data split among the deployed clients. It can be extened including sample/label/feature imbalance. Training and validation data are saved in different folders, namely data/client_i/train and data/client_i/validation. Parameter server parameters are also saved in the server folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting IID\n",
      "Client 0 | Samples 100\n",
      "Client 1 | Samples 100\n",
      "Client 2 | Samples 100\n",
      "Client 3 | Samples 100\n",
      "Client 4 | Samples 100\n",
      "Client 5 | Samples 100\n",
      "Client 6 | Samples 100\n",
      "Client 7 | Samples 100\n",
      "Client 8 | Samples 100\n",
      "Client 9 | Samples 100\n",
      "Saved train data\n",
      "Client 0 | Samples 667\n",
      "Client 1 | Samples 667\n",
      "Client 2 | Samples 667\n",
      "Client 3 | Samples 667\n",
      "Client 4 | Samples 667\n",
      "Client 5 | Samples 667\n",
      "Client 6 | Samples 667\n",
      "Client 7 | Samples 667\n",
      "Client 8 | Samples 667\n",
      "Client 9 | Samples 667\n",
      "Saved validation data\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "print('Splitting IID')\n",
    "local_size = samples  # uniform split, and a assign 'samples' samples\n",
    "# split the training dataset and create folders in data/client_#i/train\n",
    "for i in range(num_clients):\n",
    "    dir = f'data/client_{i}/train/' # create a folder with the local data for the client\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    start_index = i * local_size\n",
    "    end_index = (i + 1) * local_size\n",
    "    x_part = x_train[start_index:end_index]\n",
    "    y_part = y_train[start_index:end_index]\n",
    "        \n",
    "    print('Client {} | Samples {}'.format(i, len(y_part)))\n",
    "    np.save(dir + f'x_train.npy', x_part) # creating directories for train and validation\n",
    "    np.save(dir + f'y_train.npy', y_part)\n",
    "print(f'Saved train data')\n",
    "\n",
    "# split the validation dataset and create folders in data/client_#i/valid\n",
    "local_size = len(x_valid) // num_clients # validation data uniformly distributed across clients (other options are also possible) \n",
    "# local_size = len(x_valid)\n",
    "for i in range(num_clients):\n",
    "    dir = f'data/client_{i}/valid/' # create a folder with the local data for the client\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    start_index = i * local_size\n",
    "    end_index = (i + 1) * local_size\n",
    "    #x_part = x_valid[start_index:end_index] # uniform split of the validation set\n",
    "    #y_part = y_valid[start_index:end_index]\n",
    "    x_part = x_valid # all the clients have the same validation set (for fair comparison)\n",
    "    y_part = y_valid\n",
    "        \n",
    "    print('Client {} | Samples {}'.format(i, len(y_part)))\n",
    "    np.save(dir + f'x_valid.npy', x_part) # saving\n",
    "    np.save(dir + f'y_valid.npy', y_part)\n",
    "print(f'Saved validation data')\n",
    "\n",
    "\n",
    "x_train_clients = []\n",
    "y_train_clients = []\n",
    "x_valid_clients = []\n",
    "y_valid_clients = []\n",
    "\n",
    "# create train and valid datasets for all clients\n",
    "for k in range(num_clients):\n",
    "    x_train_clients.append(np.load(f'data/client_{k}/train/x_train.npy', allow_pickle=True))\n",
    "    y_train_clients.append(np.load(f'data/client_{k}/train/y_train.npy'))\n",
    "    x_valid_clients.append(np.load(f'data/client_{k}/valid/x_valid.npy', allow_pickle=True))\n",
    "    y_valid_clients.append(np.load(f'data/client_{k}/valid/y_valid.npy'))\n",
    "\n",
    "datasets = tuple(zip(x_train_clients, y_train_clients))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the xboost tree models locally. Decision tree models are the base models for fedxbgoostllr. Save the tree models and evaluate them separately (no federation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost classifier local model accuracy, (Client 0): 63.71814%\n",
      "xgboost classifier local model accuracy, (Client 1): 59.67016%\n",
      "xgboost classifier local model accuracy, (Client 2): 62.51874%\n",
      "xgboost classifier local model accuracy, (Client 3): 65.81709%\n",
      "xgboost classifier local model accuracy, (Client 4): 68.06597%\n",
      "xgboost classifier local model accuracy, (Client 5): 61.31934%\n",
      "xgboost classifier local model accuracy, (Client 6): 66.41679%\n",
      "xgboost classifier local model accuracy, (Client 7): 62.51874%\n",
      "xgboost classifier local model accuracy, (Client 8): 64.16792%\n",
      "xgboost classifier local model accuracy, (Client 9): 65.96702%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for each of the clients\n",
    "hyperparams = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"n_estimators\": trees_client,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"base_score\": 0.5,  # np.mean(y_train)\n",
    "    \"random_state\": 34,\n",
    "}\n",
    "if num_classes ==2:\n",
    "    hyperparams[\"objective\"] = \"binary:logistic\"\n",
    "    \n",
    "errors_clients = []\n",
    "\n",
    "for c, (x_train, y_train) in enumerate(\n",
    "        datasets\n",
    "):  # extract the dataset for the current client\n",
    "    reg = xgb.XGBClassifier(**hyperparams) # train the classifier\n",
    "    reg.fit(x_train, y_train)\n",
    "    # save model\n",
    "    checkpointpath = 'xgb_models/XGB_client_model_{}.h5'.format(c)\n",
    "    joblib.dump(reg, checkpointpath, compress=0)\n",
    "    \n",
    "    # full performance tests (accuracy and confusion matrix)\n",
    "    y_pred = reg.predict(x_valid)\n",
    "    error = accuracy_score(y_valid, y_pred)\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    print(f\"xgboost classifier local model accuracy, (Client {c}): {100*error :.5f}%\")\n",
    "    errors_clients.append(error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated XGBoost: one vs all classifier conversion (only for multiclass classification, if num classes > 2)\n",
    "\n",
    "In the following the local xgboost models are now re-trained to solve a one vs all classification problem. The outputs of these local xgboost models are treated as inputs to the fedxgboostllr global model. The global model is a 1D-CNN type with specific filter sizes (that depends on the number of local trees, the number of clients in the federation and the number of classes). The global model acts as an \"ensemble model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs all local model accuracy, (Client 0): 63.71814%\n",
      "One vs all local model accuracy, (Client 1): 59.67016%\n",
      "One vs all local model accuracy, (Client 2): 62.51874%\n",
      "One vs all local model accuracy, (Client 3): 65.81709%\n",
      "One vs all local model accuracy, (Client 4): 68.06597%\n",
      "One vs all local model accuracy, (Client 5): 61.31934%\n",
      "One vs all local model accuracy, (Client 6): 66.41679%\n",
      "One vs all local model accuracy, (Client 7): 62.51874%\n",
      "One vs all local model accuracy, (Client 8): 64.16792%\n",
      "One vs all local model accuracy, (Client 9): 65.96702%\n"
     ]
    }
   ],
   "source": [
    "################################# INDIVIDUAL CLIENTS XGBOOST REGRESSION MODEL TRAINING)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Hyperparameters for each of the clients\n",
    "hyperparams = {\n",
    "    # \"objective\": \"reg:squarederror\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"n_estimators\": trees_client,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"base_score\": 0.5,  # np.mean(y_train)\n",
    "    \"random_state\": 34,\n",
    "}\n",
    "if num_classes ==2:\n",
    "    hyperparams[\"objective\"] = \"binary:logistic\"\n",
    "    \n",
    "for c, (x_train, y_train) in enumerate(\n",
    "        datasets\n",
    "):  # extract the dataset for the current client\n",
    "    reg = OneVsRestClassifier(xgb.XGBClassifier(**hyperparams)) # regression model training\n",
    "    reg.fit(x_train, y_train)\n",
    "    # save model\n",
    "    # note: there are two ways to save a one vs rest classifier model, either using joblib or pickle, json is not supported\n",
    "    checkpointpath = 'xgb_models/XGB_client_model_fed_{}.h5'.format(c)\n",
    "    joblib.dump(reg, checkpointpath, compress=0)\n",
    "  \n",
    "# test of the one vs all local model (compared with the previous case)\n",
    "    y_pred = reg.predict(x_valid)\n",
    "    error = accuracy_score(y_valid, y_pred)\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    print(f\"One vs all local model accuracy, (Client {c}): {100*error :.5f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Federated XGBoost: extraction of the local XGBoost tree outputs\n",
    "Create a new \"dataset\" input to the global/ensemble model 1D-CNN which consists of the outputs of the XGB trees models previously trained (locally)\n",
    "\n",
    "get_trees_predictions_xgb function is used to extract the individual trees prediction outputs from the local xgboost models (modify only if needed)\n",
    "\n",
    "The general pipeline is the following (XGB trees outputs-> 1D-CNN -> predictions)\n",
    "\n",
    "NOTE: During initialization, all xgboost models (of all clients) must be shared with all clients before starting the FL process. MQTT can be used for this (but also other methods apply). In the following xgboost base models are loaded from a shared folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the data of client 0 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 1 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 2 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 3 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 4 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 5 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 6 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 7 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 8 ----------------------------------------------------------------------------------------------------\n",
      "Converting the data of client 9 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from utils import get_trees_predictions_xgb\n",
    "\n",
    "reshape_enabled = False # disable or enable the reshaping of xgboost outputs - \n",
    "# False: filter size = num_classes * trees_client, True: filter_size = trees_client\n",
    "inputs_obj = \"soft\"\n",
    "# other options: \n",
    "# objective = \"soft\" # applies a tanh activation to the xgboost tree soft outputs  \n",
    "# objective = \"binary\" # outputs of xgboost trees are binarized, \n",
    "\n",
    "if num_classes == 2:\n",
    "    reshape_enabled = False # always disabled for 2 classes (binary problem)\n",
    "   \n",
    "# load all xgboost models and prepare the data\n",
    "XGB_models = []\n",
    "for c in range(num_clients):\n",
    "    if num_classes == 2:\n",
    "        checkpointpath = 'xgb_models/XGB_client_model_{}.h5'.format(c)\n",
    "    else:\n",
    "        checkpointpath1 = 'xgb_models/XGB_client_model_fed_{}.h5'.format(c)\n",
    "    xgb = joblib.load(checkpointpath1)\n",
    "    if num_classes == 2:\n",
    "        XGB_models.append(xgb)\n",
    "    else:\n",
    "        classifiers = xgb.estimators_\n",
    "        for q in range(num_classes):\n",
    "            XGB_models.append(classifiers [q])\n",
    "\n",
    "x_xgb_trees_out = []\n",
    "y_xgb_trees_out = []\n",
    "for c, (x_train, y_train) in enumerate(datasets):  # for each client\n",
    "    print(\"Converting the data of client\", c, 100 * \"-\")\n",
    "    # XGB trees outputs (for all XGBoost trees!) corresponding to training data of client c\n",
    "    # NOTE: numclasses is needed to clip the inputs\n",
    "    x_xgb_trees_out.append(get_trees_predictions_xgb(x_train, inputs_obj, *XGB_models, numclasses=num_classes, reshape_enabled=reshape_enabled)) \n",
    "    if num_classes == 2:\n",
    "        categorical_labels = y_train\n",
    "    else:\n",
    "        categorical_labels = np.squeeze(np.eye(num_classes)[y_train.reshape(-1)])\n",
    "    y_xgb_trees_out.append(categorical_labels) # true labels now categorical\n",
    "\n",
    "datasets_out = tuple(zip(x_xgb_trees_out, y_xgb_trees_out)) # dataset_out is the new federated dataset input to 1D-CNN (XGB trees output-> 1D-CNN -> accuracy)\n",
    "\n",
    "# Validation data\n",
    "\n",
    "xgb_valid_out = get_trees_predictions_xgb(x_valid, inputs_obj, *XGB_models, numclasses=num_classes, reshape_enabled=reshape_enabled) # XGB trees outputs corresponding to validation data: to simplify the reasoning, we apply same validation set for all (other options are also feasible)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global model (ensemble model): 1D CNN FedXGBooost aggregator \n",
    "initialize the global model (or ensemble model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 10, 32)            352       \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 320)               102720    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 321       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103393 (403.88 KB)\n",
      "Trainable params: 103393 (403.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_mc # check the model in models.py\n",
    "\n",
    "filters = 32 # convolutional filters (32 ok, >32 too large, depends on tree structures) TO BE OPTIMIZED\n",
    "if reshape_enabled:\n",
    "    filter_size = trees_client\n",
    "else:\n",
    "    if num_classes == 2:\n",
    "        filter_size = trees_client # CNN filter size equal to the number of trees per client \n",
    "    else:\n",
    "        filter_size = trees_client * num_classes # CNN filter size equal to the number of trees per client * number of classes (if > 2)\n",
    "\n",
    "params_cnn = (num_clients, filter_size, trees_client, filters, num_classes)\n",
    "models_clients = []  # list of models\n",
    "\n",
    "model_global = CNN_mc(*params_cnn)  # global model\n",
    "num_layers = len(model_global.get_weights())\n",
    "\n",
    "model_global.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning process (learning of 1D CNN model parameters)\n",
    "Federated Averaging with Adam optimizer simulator. No MQTT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0/15\n",
      "Round 1/15, Client 1/10\n",
      "Round 1/15, Client 2/10\n",
      "Round 1/15, Client 3/10\n",
      "Round 1/15, Client 4/10\n",
      "Round 1/15, Client 5/10\n",
      "Round 1/15, Client 6/10\n",
      "Round 1/15, Client 7/10\n",
      "Round 1/15, Client 8/10\n",
      "Round 1/15, Client 9/10\n",
      "Round 1/15, Client 10/10\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 1.0485 - accuracy: 0.7616\n",
      "Round 2/15, Client 1/10\n",
      "Round 2/15, Client 2/10\n",
      "Round 2/15, Client 3/10\n",
      "Round 2/15, Client 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     model_client\u001b[38;5;241m.\u001b[39mset_weights(model_global\u001b[38;5;241m.\u001b[39mget_weights())  \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# update phase\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mmodel_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# train the model on the client data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     models_clients\u001b[38;5;241m.\u001b[39mappend(model_client)  \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# aggregation phase\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:873\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 873\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    876\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 176\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    169\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    396\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m--> 398\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:304\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m--> 304\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mmonomorphic_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcreteFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;49;00m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# scope. This is not the default behavior since it gets used in some\u001b[39;49;00m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;49;00m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ConcreteFunction.\u001b[39;49;00m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_func_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1066\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[1;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[0;32m   1060\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_garbage_collector \u001b[38;5;241m=\u001b[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Pairs of forward and backward functions used for computing gradients.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# These each get a reference to the FuncGraph deleter since they use the\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# FuncGraph directly.\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delayed_rewrite_functions \u001b[38;5;241m=\u001b[39m \u001b[43m_DelayedRewriteGradientFunctions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_garbage_collector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_order_tape_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_higher_order_tape_functions \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:155\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.__init__\u001b[1;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_function_pairs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph \u001b[38;5;241m=\u001b[39m func_graph\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function \u001b[38;5;241m=\u001b[39m \u001b[43matomic_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_func_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_inference_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m attrs\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:357\u001b[0m, in \u001b[0;36mfrom_func_graph\u001b[1;34m(name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_func_graph\u001b[39m(name, graph, inputs, outputs, attrs):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes an AtomicFunction from FuncGraph with transforms.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m   atomic \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_func_graph_no_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m FUNCTION_TRANSFORMS:\n\u001b[0;32m    359\u001b[0m     atomic \u001b[38;5;241m=\u001b[39m transform(atomic)\n",
      "File \u001b[1;32mc:\\Users\\Amministratore\\anaconda3\\envs\\CNRalg4TRUSTroke\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:401\u001b[0m, in \u001b[0;36mfrom_func_graph_no_transforms\u001b[1;34m(name, graph, inputs, outputs, attrs, overwrite)\u001b[0m\n\u001b[0;32m    399\u001b[0m   output_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m   fn \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphToFunction_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m      \u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperations\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    406\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    407\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    408\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    410\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# control_output_names\u001b[39;49;00m\n\u001b[0;32m    411\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name, attr_value \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    416\u001b[0m   serialized \u001b[38;5;241m=\u001b[39m attr_value\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "R = 15  # global FL rounds\n",
    "E = 10  # local epochs\n",
    "\n",
    "print(f\"Round 0/{R}\")  # init model\n",
    "\n",
    "# sets labels to categorical\n",
    "if num_classes == 2:\n",
    "    categorical_y_valid = y_valid\n",
    "else:\n",
    "    categorical_y_valid = np.squeeze(np.eye(num_classes)[y_valid.reshape(-1)])\n",
    "\n",
    "for r in range(R):  # for each round\n",
    "    \n",
    "    # update phase for each client\n",
    "    for c, (x_train_c, y_train_c) in enumerate(datasets_out):  \n",
    "        print(f\"Round {r + 1}/{R}, Client {c + 1}/{num_clients}\")\n",
    "        model_client = CNN_mc(*params_cnn)  # create a new model\n",
    "        # set global weights (no memory of prev local weights)\n",
    "        model_client.set_weights(model_global.get_weights())  \n",
    "        # update phase\n",
    "        model_client.fit(\n",
    "            x_train_c, y_train_c, epochs=E, verbose=False\n",
    "        )  # train the model on the client data\n",
    "        models_clients.append(model_client)  # save the model\n",
    "    \n",
    "    # aggregation phase\n",
    "    global_weights = []\n",
    "    for i in range(num_layers):  # aggregate the weights, no memory of prev global weights\n",
    "        global_weights.append(\n",
    "            np.sum([model.get_weights()[i] for model in models_clients], axis=0)\n",
    "            / len(models_clients)\n",
    "        )\n",
    "    model_global.set_weights(global_weights)\n",
    "\n",
    "    model_global.evaluate(xgb_valid_out, categorical_y_valid)  # evaluate the global model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "y_hat_xgb = model_global.predict(xgb_valid_out)\n",
    "if num_classes == 2:\n",
    "    y_hat_xgb_cont = y_hat_xgb >= 0.5 # binary estimator (CNN model has sigmoid output)\n",
    "else:\n",
    "    y_hat_xgb_cont = np.argmax(y_hat_xgb, axis=1)\n",
    "accuracy_fed = accuracy_score(y_valid, y_hat_xgb_cont)\n",
    "cm = confusion_matrix(y_valid, y_hat_xgb_cont)\n",
    "\n",
    "# performance and confusion matrix\n",
    "\n",
    "print(f\"Accuracy (Centralized): {accuracy_s :.2f}\")\n",
    "for c, error in enumerate(errors_clients):\n",
    "    print(f\"Accuracy (Client {c}): {error :.2f}\")\n",
    "print(f\"Accuracy (Federated): {accuracy_fed :.2f}\")\n",
    "\n",
    "# saving results\n",
    "checkpointpath = 'xgb_models/XGB_federated_model_regression_multiclass.keras'\n",
    "model_global.save(checkpointpath)\n",
    "dict_1 = {\n",
    "    \"Accuracy_centralized\": accuracy_s,\n",
    "    \"Accuracy_clients\": errors_clients,\n",
    "    \"Accuracy_federated\": accuracy_fed\n",
    "}\n",
    "sio.savemat(\n",
    "    \"results/fedXGboost_{}_features_{}_redundant_{}_classes_{}_clients_{}_trees_client_{}_train_samples_{}_reshape_{}_objective{}.mat\".format('iid',n_features,n_redundant,num_classes, num_clients, trees_client, samples, reshape_enabled, inputs_obj), dict_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNRalg4TRUSTroke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
